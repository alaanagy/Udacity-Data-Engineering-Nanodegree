{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "- The objective of this project is to work with four different datasets, Immigration data to United States, and supplementary datasets will include data on airport codes, U.S. city demographics, and temperature data.\n",
    "- We will also explore and assess the data, build a data model, perform ETL process and doing some analytics, exploration and try to find trends and patterns in our data. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col, substring\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "- Gathering data from different sources with different formatsn and load it into staging dataframes\n",
    "- Explore the data and perform cleaning process \n",
    "- Write data to parquet files in AWS S3 \n",
    "- Define data model consists of fact and dimension tables to construct star schema \n",
    "- Perform ETL process and load the data into our data model\n",
    "- Perform analysis and discover trends and patterns in our data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Datasets\n",
    "\n",
    "- [**I94 Immigration Data:**](https://www.trade.gov/national-travel-and-tourism-office)  This data comes from the US National Tourism and Trade Office.There's a sample file where we can take a look at the data in csv format before reading it all in. \n",
    "\n",
    "- [**World Temperature Data:**](https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data) This dataset came from Kaggle, it includes the temperatures of various cities in the world from 1743 to 2013.\n",
    "\n",
    "- [**U.S. City Demographic Data:**](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/)  This data comes from OpenSoft, it contains information about the demographics of all US cities and census-designated places with population greater or equal to 65,000, it comes from the US Census Bureau's 2015 American Community Survey.\n",
    "\n",
    "- [**Airport Code Table:**](https://datahub.io/core/airport-codes#data) This is a simple table of airport codes and corresponding cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### I94 Immigration Data (sample csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read immigration sample file in csv format\n",
    "imm_sample_df  = pd.read_csv('immigration_data_sample.csv')\n",
    "imm_sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "|Column|Description|\n",
    "|------|------|\n",
    "|cicid     |unique ID     |\n",
    "|i94yr     |Year     |\n",
    "|i94mon     |Month    |\n",
    "|i94cit     |3 digit code for immigrant country of birth     |\n",
    "|i94res     |3 digit code for immigrant country of residence     |\n",
    "|i94port     |Admission port|\n",
    "|arrdate     |Arrival data in USA|\n",
    "|i94mode     |Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported)|\n",
    "|i94addr     |State of arrival in USA     |\n",
    "|depdate     |Departure date of USA     |\n",
    "|i94bir     |Age of Respondent in Years     |\n",
    "|i94visa     |Visa codes collapsed into three categories|\n",
    "|count     |Used for summary statistics     |\n",
    "|dtadfile     |Character Date Field - Date added to I-94 Files|\n",
    "|visapost     |Department of State where where Visa was issued|\n",
    "|occup     |Occupation that will be performed in USA|\n",
    "|entdepa     |Arrival Flag - admitted or paroled into the USA|\n",
    "|entdepd     |Departure Flag - Departed, lost I-94 or is deceased|\n",
    "|endtdepu     |Update Flag - Either apprehended, overstayed, adjusted to perm residence     |\n",
    "|matflag     |Match flag - Match of arrival and departure records|\n",
    "|biryear     |4 digit year of birth|\n",
    "|dtaddto     |Character Date Field - Date to which admitted to USA|\n",
    "|gender     |Non-immigrant sex|\n",
    "|insnum     |INS number   |\n",
    "|airline     |Airline used to arrive in USA   |\n",
    "|admnum     |Admission Number     |\n",
    "|fltno     |Flight number of Airline used to arrive in USA   |\n",
    "|visatype     |Class of admission legally admitting the non-immigrant to temporarily stay in USA   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### World Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read Temperature data\n",
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "temperature_df = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "|Column|Description|\n",
    "|------|------|\n",
    "|dt     |Date     |\n",
    "|AverageTemperature     |Average Temperature in Celsius     |\n",
    "|AverageTemperatureUncertainty     |95% confidence interval around the average temperature   |\n",
    "|City     |city |\n",
    "|Country     |country|\n",
    "|Latitude     |city latitude|\n",
    "|Longitude     |city longitude|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### U.S. City Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read united states cities demograhpic data\n",
    "city_demographic_df  = pd.read_csv('us-cities-demographics.csv', sep = ';')\n",
    "city_demographic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "|Column|Description|\n",
    "|------|------|\n",
    "|City     |City name     |\n",
    "|State     | state of city      |\n",
    "|Median Age     |The median population age |\n",
    "|Male Population     |total male population |\n",
    "|Female Population     |total female population|\n",
    "|Total Population     |total population|\n",
    "|Number of Veterans     |Number of veterans still living in the city|\n",
    "|Foreign-born    |Number of residents who were not born in the city |\n",
    "|Average Household Size  |Average size of houses in the city|\n",
    "|State Code    |State Code|\n",
    "|Count     |Count of city's individual per race|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Airport Code Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read airport data\n",
    "airport_df  = pd.read_csv('airport-codes_csv.csv')\n",
    "airport_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "|Column|Description|\n",
    "|------|------|\n",
    "|ident     |unique identifier     |\n",
    "|type     |Airport type     |\n",
    "|name     |Airport Name  |\n",
    "|elevation_ft     |Airport altitude |\n",
    "|continent     |Continent|\n",
    "|iso_country     |ISO Code of the airport's country|\n",
    "|iso_region     |ISO Code of the airport's region|\n",
    "|municipality     |municipality where the airport is located    |\n",
    "|gps_code     |GPS code of the airport   |\n",
    "|iata_code     |IATA code of the airport |\n",
    "|local_code     |Local code of the airport|\n",
    "|coordinates     |coordinates of the airport |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Full immigration dataset using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "immigration_df = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "#immigration_df.write.parquet(\"sas_data\")\n",
    "#immigration_df = spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|  occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto|gender| insnum|airline|admnum|fltno|visatype|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "|    0|    0|     0|     0|     0|      0|      0|    239| 152592| 142457|   802|      0|    0|       1| 1881250|3088187|    238| 138429|3095921| 138429|    802|    477|414269|2982605|  83627|     0|19549|       0|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for null values\n",
    "immigration_df.select([count(when(col(c).isNull(), c)).alias(c) for c in immigration_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# creating a view of the immigration dataset\n",
    "immigration_df.createOrReplaceTempView(\"immigration_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|count(DISTINCT cicid)|\n",
      "+---------------------+\n",
      "|              3096313|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for cicid if it unique or not\n",
    "spark.sql(\"SELECT COUNT (DISTINCT cicid) FROM immigration_table\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "since the **cicid** column has unique values and no duplicates, we can consider it as a primary key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "arrdate column\n",
    "-  We need to convert the arrdate column into readable one.\n",
    "-  All dates in SAS correspond to the number of days since 1960-01-01.\n",
    "- Therfore, we compute the arrival date by adding arrdate to 1960-01-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|       admnum|fltno|visatype|arrival_date|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null|1.897628485E9| null|      B2|  2016-04-29|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df = spark.sql(\"SELECT *, date_add(to_date('1960-01-01'), arrdate) AS arrival_date FROM immigration_table\")\n",
    "# creating a view of the immigration dataset\n",
    "immigration_df.createOrReplaceTempView(\"immigration_table\")\n",
    "immigration_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Here, we can see the new column **arrival_date** which is 2016-04-29 after conversion which is corresponding to **arrdate** column which value 20573"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now, we want to make sure that departure_date is bigger than arrival_date\n",
    "\n",
    "**depdate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_df = spark.sql(\"\"\"SELECT *, CASE \n",
    "                        WHEN depdate >= 1.0 THEN date_add(to_date('1960-01-01'), depdate)\n",
    "                        WHEN depdate IS NULL THEN NULL\n",
    "                        ELSE 'N/A' END AS departure_date \n",
    "                        FROM immigration_table\"\"\")\n",
    "\n",
    "immigration_df.createOrReplaceTempView(\"immigration_table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     375|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(*) FROM immigration_table WHERE departure_date <= arrival_date\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    " Since the number of affected rows is relatively small, we can easily drop these rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+------------+--------------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|      admnum|fltno|visatype|arrival_date|departure_date|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+------------+--------------+\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|6.66643185E8|   93|      B2|  2016-04-01|    2016-08-25|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+------------+--------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df = spark.sql(\"\"\"SELECT *\n",
    "                            FROM immigration_table\n",
    "                            WHERE departure_date >= arrival_date\n",
    "\"\"\")\n",
    "\n",
    "immigration_df.createOrReplaceTempView(\"immigration_table\")\n",
    "immigration_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check for result \n",
    "spark.sql(\"SELECT COUNT(*) FROM immigration_table WHERE departure_date <= arrival_date\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The **i94mode** column has four values as following\n",
    "- 1 = \"Air\"\n",
    "- 2 = \"Sea\"\n",
    "- 3 = \"Land\"\n",
    "- 9 = \"Not reported\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|i94mode|  count|\n",
      "+-------+-------+\n",
      "|   null|    238|\n",
      "|    1.0|2871184|\n",
      "|    3.0|  61572|\n",
      "|    2.0|  17970|\n",
      "|    9.0|   2517|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT i94mode, count(*) as count FROM immigration_table GROUP BY i94mode\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+------------+--------------+------------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|      admnum|fltno|visatype|arrival_date|departure_date|arrival_mode|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+------------+--------------+------------+\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|6.66643185E8|   93|      B2|  2016-04-01|    2016-08-25|         Air|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+------------+--------------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df = spark.sql(\"\"\"SELECT *, CASE \n",
    "                        WHEN i94mode = 1.0 THEN 'Air' \n",
    "                        WHEN i94mode = 2.0 THEN 'Sea'\n",
    "                        WHEN i94mode = 3.0 THEN 'Land'\n",
    "                        WHEN i94mode = 9.0 THEN 'Not_reported'\n",
    "                        ELSE 'Not_reported'  END AS arrival_mode   FROM immigration_table\"\"\")\n",
    "\n",
    "immigration_df.createOrReplaceTempView(\"immigration_table\")\n",
    "immigration_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The **I94VISA** column has three values as following\n",
    "- 1 = \"Business\"\n",
    "- 2 = \"Pleasure\"\n",
    "- 3 = \"Student\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|i94visa|  count|\n",
      "+-------+-------+\n",
      "|    1.0| 508764|\n",
      "|    3.0|  30305|\n",
      "|    2.0|2414412|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT i94visa, count(*) as count FROM immigration_table GROUP BY i94visa\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+------------+--------------+------------+---------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|      admnum|fltno|visatype|arrival_date|departure_date|arrival_mode|visa_type|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+------------+--------------+------------+---------+\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|6.66643185E8|   93|      B2|  2016-04-01|    2016-08-25|         Air| Pleasure|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+------------+--------------+------------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df = spark.sql(\"\"\"SELECT *, CASE \n",
    "                        WHEN i94visa = 1.0 THEN 'Business' \n",
    "                        WHEN i94visa  = 2.0 THEN 'Pleasure'\n",
    "                        WHEN i94visa = 3.0 THEN 'Student'    END AS visa_type   FROM immigration_table\"\"\")\n",
    "\n",
    "immigration_df.createOrReplaceTempView(\"immigration_table\")\n",
    "immigration_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|gender|count(1)|\n",
      "+------+--------+\n",
      "|     F| 1228646|\n",
      "|  null|  407456|\n",
      "|     M| 1316305|\n",
      "|     U|     238|\n",
      "|     X|     836|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gender column \n",
    "spark.sql(\"SELECT gender, count(*)  FROM immigration_table GROUP BY gender\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+------------+--------------+------------+---------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|      admnum|fltno|visatype|arrival_date|departure_date|arrival_mode|visa_type|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+------------+--------------+------------+---------+\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|6.66643185E8|   93|      B2|  2016-04-01|    2016-08-25|         Air| Pleasure|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+------------+--------------+------------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df = spark.sql(\"Select * From immigration_table where gender IN ('M', 'F')\")\n",
    "immigration_df.createOrReplaceTempView(\"immigration_table\")\n",
    "immigration_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-----+-----------------------+---------------------------+--------+------------+--------------+------------+-------------+----+---------+-----+----------+------+-------+--------------+----------+\n",
      "|  id|  year|month|immigrant_birth_country|immigrant_residence_country|adm_port|arrival_date|departure_date|arrival_mode|arrival_state| age|visa_type|count|birth_year|gender|airline| admission_num|flight_num|\n",
      "+----+------+-----+-----------------------+---------------------------+--------+------------+--------------+------------+-------------+----+---------+-----+----------+------+-------+--------------+----------+\n",
      "|15.0|2016.0|  4.0|                  101.0|                      101.0|     WAS|  2016-04-01|    2016-08-25|         Air|           MI|55.0| Pleasure|  1.0|    1961.0|     M|     OS|  6.66643185E8|        93|\n",
      "|27.0|2016.0|  4.0|                  101.0|                      101.0|     BOS|  2016-04-01|    2016-04-05|         Air|           MA|58.0| Business|  1.0|    1958.0|     M|     LH|9.247876383E10|     00422|\n",
      "|28.0|2016.0|  4.0|                  101.0|                      101.0|     ATL|  2016-04-01|    2016-04-05|         Air|           MA|56.0| Business|  1.0|    1960.0|     F|     LH|9.247890033E10|     00422|\n",
      "|29.0|2016.0|  4.0|                  101.0|                      101.0|     ATL|  2016-04-01|    2016-04-17|         Air|           MA|62.0| Pleasure|  1.0|    1954.0|     M|     AZ|9.250378143E10|     00614|\n",
      "|30.0|2016.0|  4.0|                  101.0|                      101.0|     ATL|  2016-04-01|    2016-05-04|         Air|           NJ|49.0| Pleasure|  1.0|    1967.0|     M|     OS|9.247020943E10|     00089|\n",
      "+----+------+-----+-----------------------+---------------------------+--------+------------+--------------+------------+-------------+----+---------+-----+----------+------+-------+--------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df = spark.sql(\"\"\"Select cicid as id, i94yr as year, i94mon as month,\n",
    "                            i94cit as immigrant_birth_country, i94res as immigrant_residence_country,\n",
    "                            i94port as adm_port, arrival_date, departure_date,  arrival_mode, i94addr as arrival_state,\n",
    "                            i94bir as age, visa_type, count, biryear as birth_year, gender, airline,\n",
    "                            admnum as admission_num , fltno as flight_num\n",
    "                            From immigration_table\n",
    "\"\"\")\n",
    "immigration_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### World Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8599212 entries, 0 to 8599211\n",
      "Data columns (total 7 columns):\n",
      "dt                               object\n",
      "AverageTemperature               float64\n",
      "AverageTemperatureUncertainty    float64\n",
      "City                             object\n",
      "Country                          object\n",
      "Latitude                         object\n",
      "Longitude                        object\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 459.2+ MB\n"
     ]
    }
   ],
   "source": [
    "temperature_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8599212, 7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt                                    0\n",
       "AverageTemperature               364130\n",
       "AverageTemperatureUncertainty    364130\n",
       "City                                  0\n",
       "Country                               0\n",
       "Latitude                              0\n",
       "Longitude                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for nan values\n",
    "temperature_df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for any duplicates\n",
    "temperature_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Keep only data for the United States to make it useful with our immigration data\n",
    "temperature_df = temperature_df[temperature_df['Country']=='United States']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As we focus on air travelling data, so we will include only data with date after 1950, after the finish of the second world war and the return of air travelling lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert the date to datetime objects\n",
    "temperature_df['date'] = pd.to_datetime(temperature_df.dt)\n",
    "\n",
    "# Remove all dates before 1950\n",
    "temperature_df = temperature_df[temperature_df['date']>\"1950-01-01\"]\n",
    "temperature_df = temperature_df.drop('dt', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49116</th>\n",
       "      <td>10.067</td>\n",
       "      <td>0.332</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>1950-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49117</th>\n",
       "      <td>11.824</td>\n",
       "      <td>0.343</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>1950-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49118</th>\n",
       "      <td>16.963</td>\n",
       "      <td>0.315</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>1950-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49119</th>\n",
       "      <td>21.444</td>\n",
       "      <td>0.250</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>1950-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49120</th>\n",
       "      <td>25.832</td>\n",
       "      <td>0.202</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>1950-06-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "49116              10.067                          0.332  Abilene   \n",
       "49117              11.824                          0.343  Abilene   \n",
       "49118              16.963                          0.315  Abilene   \n",
       "49119              21.444                          0.250  Abilene   \n",
       "49120              25.832                          0.202  Abilene   \n",
       "\n",
       "             Country Latitude Longitude       date  \n",
       "49116  United States   32.95N   100.53W 1950-02-01  \n",
       "49117  United States   32.95N   100.53W 1950-03-01  \n",
       "49118  United States   32.95N   100.53W 1950-04-01  \n",
       "49119  United States   32.95N   100.53W 1950-05-01  \n",
       "49120  United States   32.95N   100.53W 1950-06-01  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AverageTemperature               1\n",
       "AverageTemperatureUncertainty    1\n",
       "City                             0\n",
       "Country                          0\n",
       "Latitude                         0\n",
       "Longitude                        0\n",
       "date                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for nan values\n",
    "temperature_df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287781</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>United States</td>\n",
       "      <td>61.88N</td>\n",
       "      <td>151.13W</td>\n",
       "      <td>2013-09-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AverageTemperature  AverageTemperatureUncertainty       City  \\\n",
       "287781                 NaN                            NaN  Anchorage   \n",
       "\n",
       "              Country Latitude Longitude       date  \n",
       "287781  United States   61.88N   151.13W 2013-09-01  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df[temperature_df.AverageTemperature.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop row that has null values\n",
    "temperature_df.dropna(subset=['AverageTemperature'], how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AverageTemperature               0\n",
       "AverageTemperatureUncertainty    0\n",
       "City                             0\n",
       "Country                          0\n",
       "Latitude                         0\n",
       "Longitude                        0\n",
       "date                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for nan values\n",
    "temperature_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### U.S. City Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_demographic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2891, 12)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_demographic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2891 non-null object\n",
      "State                     2891 non-null object\n",
      "Median Age                2891 non-null float64\n",
      "Male Population           2888 non-null float64\n",
      "Female Population         2888 non-null float64\n",
      "Total Population          2891 non-null int64\n",
      "Number of Veterans        2878 non-null float64\n",
      "Foreign-born              2878 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2891 non-null object\n",
      "Race                      2891 non-null object\n",
      "Count                     2891 non-null int64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.1+ KB\n"
     ]
    }
   ],
   "source": [
    "city_demographic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for any duplicates\n",
    "city_demographic_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                       0\n",
       "State                      0\n",
       "Median Age                 0\n",
       "Male Population            3\n",
       "Female Population          3\n",
       "Total Population           0\n",
       "Number of Veterans        13\n",
       "Foreign-born              13\n",
       "Average Household Size    16\n",
       "State Code                 0\n",
       "Race                       0\n",
       "Count                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "city_demographic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop null values from our dataframe\n",
    "city_demographic_df.dropna(subset=['Average Household Size'], how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                      0\n",
       "State                     0\n",
       "Median Age                0\n",
       "Male Population           0\n",
       "Female Population         0\n",
       "Total Population          0\n",
       "Number of Veterans        0\n",
       "Foreign-born              0\n",
       "Average Household Size    0\n",
       "State Code                0\n",
       "Race                      0\n",
       "Count                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "city_demographic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Airport data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55075, 12)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident               0\n",
       "type                0\n",
       "name                0\n",
       "elevation_ft     7006\n",
       "continent       27719\n",
       "iso_country       247\n",
       "iso_region          0\n",
       "municipality     5676\n",
       "gps_code        14045\n",
       "iata_code       45886\n",
       "local_code      26389\n",
       "coordinates         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chekc for missing values\n",
    "airport_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We have 247 null entries in country column, so we will drop them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop null values from iso_counrty column\n",
    "airport_df.dropna(subset=['iso_country'], how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident               0\n",
       "type                0\n",
       "name                0\n",
       "elevation_ft     6990\n",
       "continent       27719\n",
       "iso_country         0\n",
       "iso_region          0\n",
       "municipality     5574\n",
       "gps_code        13872\n",
       "iata_code       45670\n",
       "local_code      26142\n",
       "coordinates         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chekc for missing values\n",
    "airport_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for duplicates\n",
    "airport_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "small_airport     33734\n",
       "heliport          11287\n",
       "medium_airport     4539\n",
       "closed             3602\n",
       "seaplane_base      1016\n",
       "large_airport       626\n",
       "balloonport          24\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "we will include only meaningful airports which will help us in our immigration data as \n",
    "- closed means that it is a closed airport\n",
    "- ballonport, heliport and seaplaneport will not help us in our immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_df.query(\" type in ('small_airport','large_airport','medium_airport')\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "small_airport     33734\n",
       "medium_airport     4539\n",
       "large_airport       626\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iso_country\n",
       "AE       29\n",
       "AF       59\n",
       "AG        3\n",
       "AI        1\n",
       "AL        6\n",
       "AM        9\n",
       "AO       94\n",
       "AQ       25\n",
       "AR      691\n",
       "AS        4\n",
       "AT       55\n",
       "AU     1730\n",
       "AW        1\n",
       "AZ       33\n",
       "BA       13\n",
       "BB        3\n",
       "BD       15\n",
       "BE       52\n",
       "BF       51\n",
       "BG      104\n",
       "BH        3\n",
       "BI        6\n",
       "BJ       10\n",
       "BL        1\n",
       "BM        1\n",
       "BN        2\n",
       "BO      196\n",
       "BQ        3\n",
       "BR     3204\n",
       "BS       60\n",
       "      ...  \n",
       "TJ       15\n",
       "TL       11\n",
       "TM       20\n",
       "TN       14\n",
       "TO        6\n",
       "TR      114\n",
       "TT        3\n",
       "TV        1\n",
       "TW       31\n",
       "TZ      204\n",
       "UA      135\n",
       "UG       36\n",
       "UM        3\n",
       "US    14582\n",
       "UY       52\n",
       "UZ      173\n",
       "VC        5\n",
       "VE      505\n",
       "VG        3\n",
       "VI        2\n",
       "VN       37\n",
       "VU       32\n",
       "WF        2\n",
       "WS        4\n",
       "XK        2\n",
       "YE       25\n",
       "YT        1\n",
       "ZA      473\n",
       "ZM      102\n",
       "ZW      136\n",
       "Name: iso_country, Length: 238, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the countries where airports located\n",
    "airport_df.groupby('iso_country')['iso_country'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**This dataset contains airport data for many countries. Our immigration dataset only contains entries into the US, thus we will reduce our data to include entries with iso_country column to be United states for the purpose of data modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_df = airport_df[airport_df['iso_country'] == 'US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    14582\n",
       "Name: iso_country, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.iso_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iso_region\n",
       "US-AK      589\n",
       "US-AL      198\n",
       "US-AR      292\n",
       "US-AZ      215\n",
       "US-CA      554\n",
       "US-CO      289\n",
       "US-CT       56\n",
       "US-DC        2\n",
       "US-DE       36\n",
       "US-FL      523\n",
       "US-GA      365\n",
       "US-HI       36\n",
       "US-IA      232\n",
       "US-ID      240\n",
       "US-IL      581\n",
       "US-IN      487\n",
       "US-KS      373\n",
       "US-KY      165\n",
       "US-LA      283\n",
       "US-MA       79\n",
       "US-MD      157\n",
       "US-ME      122\n",
       "US-MI      380\n",
       "US-MN      362\n",
       "US-MO      411\n",
       "US-MS      212\n",
       "US-MT      255\n",
       "US-NC      349\n",
       "US-ND      297\n",
       "US-NE      259\n",
       "US-NH       54\n",
       "US-NJ      116\n",
       "US-NM      150\n",
       "US-NV      115\n",
       "US-NY      404\n",
       "US-OH      493\n",
       "US-OK      372\n",
       "US-OR      357\n",
       "US-PA      486\n",
       "US-RI       10\n",
       "US-SC      173\n",
       "US-SD      162\n",
       "US-TN      228\n",
       "US-TX     1556\n",
       "US-U-A       7\n",
       "US-UT      105\n",
       "US-VA      311\n",
       "US-VT       66\n",
       "US-WA      382\n",
       "US-WI      458\n",
       "US-WV       83\n",
       "US-WY       95\n",
       "Name: iso_region, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the region(state) where airports located\n",
    "airport_df.groupby('iso_region')['iso_region'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "It seems that U-A is an error, so we will drop it and extract state name from iso_region column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iso_region\n",
       "US-AK     589\n",
       "US-AL     198\n",
       "US-AR     292\n",
       "US-AZ     215\n",
       "US-CA     554\n",
       "US-CO     289\n",
       "US-CT      56\n",
       "US-DC       2\n",
       "US-DE      36\n",
       "US-FL     523\n",
       "US-GA     365\n",
       "US-HI      36\n",
       "US-IA     232\n",
       "US-ID     240\n",
       "US-IL     581\n",
       "US-IN     487\n",
       "US-KS     373\n",
       "US-KY     165\n",
       "US-LA     283\n",
       "US-MA      79\n",
       "US-MD     157\n",
       "US-ME     122\n",
       "US-MI     380\n",
       "US-MN     362\n",
       "US-MO     411\n",
       "US-MS     212\n",
       "US-MT     255\n",
       "US-NC     349\n",
       "US-ND     297\n",
       "US-NE     259\n",
       "US-NH      54\n",
       "US-NJ     116\n",
       "US-NM     150\n",
       "US-NV     115\n",
       "US-NY     404\n",
       "US-OH     493\n",
       "US-OK     372\n",
       "US-OR     357\n",
       "US-PA     486\n",
       "US-RI      10\n",
       "US-SC     173\n",
       "US-SD     162\n",
       "US-TN     228\n",
       "US-TX    1556\n",
       "US-UT     105\n",
       "US-VA     311\n",
       "US-VT      66\n",
       "US-WA     382\n",
       "US-WI     458\n",
       "US-WV      83\n",
       "US-WY      95\n",
       "Name: iso_region, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df = airport_df[airport_df['iso_region'] != 'US-U-A']\n",
    "\n",
    "# check for cleaned iso_region column \n",
    "airport_df.groupby('iso_region')['iso_region'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        KS\n",
       "2        AK\n",
       "3        AL\n",
       "5        OK\n",
       "6        AZ\n",
       "7        CA\n",
       "8        CA\n",
       "11       FL\n",
       "13       FL\n",
       "14       GA\n",
       "17       ID\n",
       "18       KS\n",
       "20       IL\n",
       "22       IL\n",
       "23       KS\n",
       "24       KY\n",
       "27       LA\n",
       "28       MD\n",
       "30       MN\n",
       "31       MO\n",
       "33       NJ\n",
       "34       NC\n",
       "37       NY\n",
       "38       OH\n",
       "40       OK\n",
       "43       PA\n",
       "45       OR\n",
       "46       SC\n",
       "47       SD\n",
       "50       TN\n",
       "         ..\n",
       "52740    MN\n",
       "52741    MN\n",
       "52742    ND\n",
       "52743    MI\n",
       "52744    IA\n",
       "52745    WI\n",
       "52746    MI\n",
       "52747    MI\n",
       "52748    MI\n",
       "52749    MI\n",
       "52750    MI\n",
       "52751    ND\n",
       "54550    AK\n",
       "54551    AK\n",
       "54552    AK\n",
       "54557    AK\n",
       "54559    AK\n",
       "54560    AK\n",
       "54562    AK\n",
       "54563    AK\n",
       "54564    AK\n",
       "54565    AK\n",
       "54570    AK\n",
       "54571    AK\n",
       "54573    AK\n",
       "54574    AK\n",
       "54575    MI\n",
       "54576    AK\n",
       "54577    AZ\n",
       "54896    AK\n",
       "Name: state, Length: 14575, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df['state'] = airport_df['iso_region'].str[3:]\n",
    "airport_df.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "      <td>KS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00AS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Fulton Airport</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OK</td>\n",
       "      <td>Alex</td>\n",
       "      <td>00AS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AS</td>\n",
       "      <td>-97.8180194, 34.9428028</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00AZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cordes Airport</td>\n",
       "      <td>3810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AZ</td>\n",
       "      <td>Cordes</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>-112.16500091552734, 34.305599212646484</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                  name  elevation_ft continent  \\\n",
       "1  00AA  small_airport  Aero B Ranch Airport        3435.0       NaN   \n",
       "2  00AK  small_airport          Lowell Field         450.0       NaN   \n",
       "3  00AL  small_airport          Epps Airpark         820.0       NaN   \n",
       "5  00AS  small_airport        Fulton Airport        1100.0       NaN   \n",
       "6  00AZ  small_airport        Cordes Airport        3810.0       NaN   \n",
       "\n",
       "  iso_country iso_region  municipality gps_code iata_code local_code  \\\n",
       "1          US      US-KS         Leoti     00AA       NaN       00AA   \n",
       "2          US      US-AK  Anchor Point     00AK       NaN       00AK   \n",
       "3          US      US-AL       Harvest     00AL       NaN       00AL   \n",
       "5          US      US-OK          Alex     00AS       NaN       00AS   \n",
       "6          US      US-AZ        Cordes     00AZ       NaN       00AZ   \n",
       "\n",
       "                               coordinates state  \n",
       "1                   -101.473911, 38.704022    KS  \n",
       "2              -151.695999146, 59.94919968    AK  \n",
       "3    -86.77030181884766, 34.86479949951172    AL  \n",
       "5                  -97.8180194, 34.9428028    OK  \n",
       "6  -112.16500091552734, 34.305599212646484    AZ  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### fact table\n",
    "Immigration dataset is our main data, so we will construct our **fact_immigration** table from it and fact table fields will be as following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- id\n",
    "- citizenship_country\n",
    "- residence_country\n",
    "- city\n",
    "- state\n",
    "- arrival_date\n",
    "- departure_date\n",
    "- age\n",
    "- visa_type\n",
    "- gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Dimensions tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**airports_dim** \n",
    "we will include our scope of interest fields\n",
    "- ident\n",
    "- type\n",
    "- name\n",
    "- elevation_ft\n",
    "- state\n",
    "- municipality\n",
    "- iata_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**demographic_dim**\n",
    "we will include our scope of interest fields\n",
    "\n",
    "- City\n",
    "- state\n",
    "- median_age\n",
    "- male_population\n",
    "- female_population\n",
    "- total population\n",
    "- Foreign_born\n",
    "- Average_Household_Size\n",
    "- Race\n",
    "- Count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**temperature_dim**\n",
    "we will include our scope of interest fields\n",
    "\n",
    "- date\n",
    "- City\n",
    "- average_temperature\n",
    "- average_termperature_uncertainty\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**time_dim**\n",
    "we will include our scope of interest fields\n",
    "\n",
    "- date\n",
    "- year\n",
    "- month\n",
    "- day\n",
    "- week\n",
    "- weekday\n",
    "- dayofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Building the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Immigration data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Staging the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code      country\n",
       "0   582      MEXICO \n",
       "1   236  AFGHANISTAN\n",
       "2   101      ALBANIA\n",
       "3   316      ALGERIA\n",
       "4   102      ANDORRA"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_codes_df = pd.read_csv('countries_codes.csv')\n",
    "i94airports_codes_df = pd.read_csv('i94port_codes.csv')\n",
    "countries_codes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>location</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code                  location state\n",
       "0  ALC                     ALCAN    AK\n",
       "1  ANC                 ANCHORAGE    AK\n",
       "2  BAR  BAKER AAF - BAKER ISLAND    AK\n",
       "3  DAC             DALTONS CACHE    AK\n",
       "4  PIZ    DEW STATION PT LAY DEW    AK"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all entries with null values\n",
    "i94airports_codes_df = i94airports_codes_df[~i94airports_codes_df.state.isna()].copy()\n",
    "i94airports_codes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# let's convert the data dictionaries to views in our spark context to perform SQL operations with them\n",
    "spark_df_country_codes = spark.createDataFrame(countries_codes_df)\n",
    "spark_df_country_codes .createOrReplaceTempView(\"country_codes\")\n",
    "\n",
    "\n",
    "\n",
    "spark_df_i94airports_codes = spark.createDataFrame(i94airports_codes_df)\n",
    "spark_df_i94airports_codes .createOrReplaceTempView(\"i94port_codes\")\n",
    "\n",
    "immigration_df.createOrReplaceTempView(\"immigration_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#country of citizenship\n",
    "spark.sql(\"\"\"\n",
    "SELECT im.*, cc.country AS citizenship_country\n",
    "FROM immigration_table im\n",
    "JOIN country_codes cc\n",
    "ON im.immigrant_birth_country = cc.code\n",
    "\"\"\").createOrReplaceTempView(\"immigration_table\")\n",
    "\n",
    "\n",
    "#country of residence\n",
    "spark.sql(\"\"\"\n",
    "SELECT im.*, cc.country AS residence_country\n",
    "FROM immigration_table im\n",
    "JOIN country_codes cc\n",
    "ON im.immigrant_residence_country = cc.code\n",
    "\"\"\").createOrReplaceTempView(\"immigration_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add entry_port names and entry port states to the view\n",
    "spark.sql(\"\"\"\n",
    "SELECT im.*, pc.location AS entry_port, pc.state AS entry_port_state\n",
    "FROM immigration_table im \n",
    "JOIN i94port_codes pc\n",
    "ON im.adm_port = pc.code\n",
    "\"\"\").createOrReplaceTempView(\"immigration_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Insert the data into immigration fact table\n",
    "immigration_fact = spark.sql(\"\"\"\n",
    "                        SELECT \n",
    "                            id, \n",
    "                            citizenship_country,\n",
    "                            residence_country,\n",
    "                            TRIM(UPPER (entry_port)) AS city,\n",
    "                            TRIM(UPPER (entry_port_state)) AS state,\n",
    "                            arrival_date,\n",
    "                            departure_date,\n",
    "                            CAST(age as int),\n",
    "                            visa_type,\n",
    "                            gender\n",
    "\n",
    "                        FROM immigration_table\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-----------------+------+-----+------------+--------------+---+---------+------+\n",
      "|       id|citizenship_country|residence_country|  city|state|arrival_date|departure_date|age|visa_type|gender|\n",
      "+---------+-------------------+-----------------+------+-----+------------+--------------+---+---------+------+\n",
      "|4041803.0|            GERMANY|          GERMANY|BANGOR|   ME|  2016-04-22|    2016-05-07| 49| Business|     F|\n",
      "|4041805.0|            GERMANY|          GERMANY|BANGOR|   ME|  2016-04-22|    2016-05-07| 45| Business|     M|\n",
      "|4041806.0|            GERMANY|          GERMANY|BANGOR|   ME|  2016-04-22|    2016-05-07| 25| Business|     M|\n",
      "| 452706.0|             NORWAY|           NORWAY|BANGOR|   ME|  2016-04-03|    2016-04-05| 38| Business|     M|\n",
      "|4670699.0|            DENMARK|          DENMARK|BANGOR|   ME|  2016-04-25|    2016-04-27| 43| Business|     M|\n",
      "+---------+-------------------+-----------------+------+-----+------------+--------------+---+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_fact.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Airports data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident            object\n",
       "type             object\n",
       "name             object\n",
       "elevation_ft    float64\n",
       "continent        object\n",
       "iso_country      object\n",
       "iso_region       object\n",
       "municipality     object\n",
       "gps_code         object\n",
       "iata_code        object\n",
       "local_code       object\n",
       "coordinates      object\n",
       "state            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"ident\", StringType(), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"elevation_ft\", FloatType(), True),\n",
    "    StructField(\"continent\", StringType(), True),\n",
    "    StructField(\"iso_country\", StringType(), True),\n",
    "    StructField(\"iso_region\", StringType(), True),\n",
    "    StructField(\"municipality\", StringType(), True),\n",
    "    StructField(\"gps_code\", StringType(), True), \n",
    "    StructField(\"iata_code\", StringType(), True),\n",
    "    StructField(\"local_code\", StringType(), True),\n",
    "    StructField(\"coordinates\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "\n",
    "spark_df_airports = spark.createDataFrame(airport_df, schema)\n",
    "spark_df_airports.createOrReplaceTempView(\"airports\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Insert the data into airports dimension table \n",
    "airports_dim = spark.sql(\"\"\"\n",
    "                        SELECT \n",
    "                            ident, \n",
    "                            type,\n",
    "                            name,\n",
    "                            elevation_ft,\n",
    "                            state,\n",
    "                            TRIM(UPPER(municipality)) AS municipality,\n",
    "                            iata_code\n",
    "\n",
    "                        FROM airports\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+-----+------------+---------+\n",
      "|ident|         type|                name|elevation_ft|state|municipality|iata_code|\n",
      "+-----+-------------+--------------------+------------+-----+------------+---------+\n",
      "| 00AA|small_airport|Aero B Ranch Airport|      3435.0|   KS|       LEOTI|      NaN|\n",
      "| 00AK|small_airport|        Lowell Field|       450.0|   AK|ANCHOR POINT|      NaN|\n",
      "| 00AL|small_airport|        Epps Airpark|       820.0|   AL|     HARVEST|      NaN|\n",
      "| 00AS|small_airport|      Fulton Airport|      1100.0|   OK|        ALEX|      NaN|\n",
      "| 00AZ|small_airport|      Cordes Airport|      3810.0|   AZ|      CORDES|      NaN|\n",
      "+-----+-------------+--------------------+------------+-----+------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports_dim.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### City Demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark_df_demographics = spark.createDataFrame(city_demographic_df)\n",
    "spark_df_demographics.createOrReplaceTempView(\"demographics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: double (nullable = true)\n",
      " |-- Male Population: double (nullable = true)\n",
      " |-- Female Population: double (nullable = true)\n",
      " |-- Total Population: long (nullable = true)\n",
      " |-- Number of Veterans: double (nullable = true)\n",
      " |-- Foreign-born: double (nullable = true)\n",
      " |-- Average Household Size: double (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df_demographics.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# insert data into the demographics dimension table\n",
    "demographics_dim = spark.sql(\"\"\"\n",
    "                                SELECT  City, \n",
    "                                        State, \n",
    "                                        `Median Age` AS median_age, \n",
    "                                        `Male Population` AS male_population, \n",
    "                                        `Female Population` AS female_population, \n",
    "                                        `Total Population` AS total_population, \n",
    "                                        `Foreign-born` AS foreign_born, \n",
    "                                        `Average Household Size` AS average_household_size, \n",
    "                                        `State Code` AS state, \n",
    "                                        Race, \n",
    "                                        Count\n",
    "                                FROM demographics\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------+----------------------+-----+--------------------+-----+\n",
      "|            City|        State|median_age|male_population|female_population|total_population|foreign_born|average_household_size|state|                Race|Count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------+----------------------+-----+--------------------+-----+\n",
      "|   Silver Spring|     Maryland|      33.8|        40601.0|          41862.0|           82463|     30908.0|                   2.6|   MD|  Hispanic or Latino|25924|\n",
      "|          Quincy|Massachusetts|      41.0|        44129.0|          49500.0|           93629|     32935.0|                  2.39|   MA|               White|58723|\n",
      "|          Hoover|      Alabama|      38.5|        38040.0|          46799.0|           84839|      8229.0|                  2.58|   AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|   California|      34.5|        88127.0|          87105.0|          175232|     33878.0|                  3.18|   CA|Black or African-...|24437|\n",
      "|          Newark|   New Jersey|      34.6|       138040.0|         143873.0|          281913|     86253.0|                  2.73|   NJ|               White|76402|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------+----------------------+-----+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics_dim.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49116</th>\n",
       "      <td>10.067</td>\n",
       "      <td>0.332</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>1950-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49117</th>\n",
       "      <td>11.824</td>\n",
       "      <td>0.343</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>1950-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49118</th>\n",
       "      <td>16.963</td>\n",
       "      <td>0.315</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>1950-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49119</th>\n",
       "      <td>21.444</td>\n",
       "      <td>0.250</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>1950-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49120</th>\n",
       "      <td>25.832</td>\n",
       "      <td>0.202</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>1950-06-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "49116              10.067                          0.332  Abilene   \n",
       "49117              11.824                          0.343  Abilene   \n",
       "49118              16.963                          0.315  Abilene   \n",
       "49119              21.444                          0.250  Abilene   \n",
       "49120              25.832                          0.202  Abilene   \n",
       "\n",
       "             Country Latitude Longitude       date  \n",
       "49116  United States   32.95N   100.53W 1950-02-01  \n",
       "49117  United States   32.95N   100.53W 1950-03-01  \n",
       "49118  United States   32.95N   100.53W 1950-04-01  \n",
       "49119  United States   32.95N   100.53W 1950-05-01  \n",
       "49120  United States   32.95N   100.53W 1950-06-01  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark_df_temperature = spark.createDataFrame(temperature_df)\n",
    "spark_df_temperature.createOrReplaceTempView(\"temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df_temperature.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# insert data into the demographics dimension table\n",
    "temperature_dim = spark.sql(\"\"\"\n",
    "                                SELECT  DISTINCT cast(date as date), \n",
    "                                        City,                   \n",
    "                                        AVG(AverageTemperature) OVER (PARTITION BY date, City) AS average_temperature, \n",
    "                                        AVG(AverageTemperatureUncertainty)  OVER (PARTITION BY date, City) AS average_termperature_uncertainty\n",
    "                                FROM temperature\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+-------------------+--------------------------------+\n",
      "|      date|            City|average_temperature|average_termperature_uncertainty|\n",
      "+----------+----------------+-------------------+--------------------------------+\n",
      "|1957-04-01|            Reno|              9.415|                           0.477|\n",
      "|1977-04-01|          Irvine|             14.277|                           0.259|\n",
      "|1977-06-01|          Tacoma|             13.556|                           0.205|\n",
      "|1994-07-01|     Springfield| 24.105333333333334|             0.27466666666666667|\n",
      "|2006-12-01|          Tucson|              8.923|                           0.246|\n",
      "|1956-01-01|      Long Beach|             12.837|                           0.478|\n",
      "|1956-01-01|       Roseville|              3.732|                           0.267|\n",
      "|1973-10-01|     New Orleans|             22.781|                           0.259|\n",
      "|1992-08-01|       Lancaster|  25.76400000000001|              0.6659999999999999|\n",
      "|2013-03-01|         Phoenix|             18.188|             0.29600000000000004|\n",
      "|1978-03-01|East Los Angeles|              13.48|                           0.249|\n",
      "|1982-08-01|        Thornton|             21.711|                           0.224|\n",
      "|1992-03-01|            Reno|              8.168|                           0.299|\n",
      "|2004-02-01|         Detroit|             -3.149|                           0.327|\n",
      "|1953-08-01|         Jackson|             27.026|             0.21600000000000005|\n",
      "|1996-09-01|         Garland|             23.456|                           0.239|\n",
      "|1971-12-01|         Seattle|             -0.359|             0.16699999999999998|\n",
      "|1998-05-01|          Topeka|              21.15|                           0.195|\n",
      "|1998-10-01|      Pittsburgh| 11.914000000000001|             0.16399999999999998|\n",
      "|1971-06-01|       Worcester|             18.848|                           0.159|\n",
      "+----------+----------------+-------------------+--------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_dim.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract all distinct dates from arrival and departure dates to create dimension table\n",
    "time_dim = spark.sql(\"\"\"\n",
    "                SELECT DISTINCT arrival_date AS date\n",
    "                FROM immigration_table\n",
    "                UNION\n",
    "                SELECT DISTINCT departure_date AS date\n",
    "                FROM immigration_table\n",
    "                WHERE departure_date IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "time_dim.createOrReplaceTempView(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# insert data into the demographics dimension table\n",
    "time_dim = spark.sql(\"\"\"\n",
    "                                SELECT  date, \n",
    "                                        YEAR(date) AS year, \n",
    "                                        MONTH(date) AS month, \n",
    "                                        DAY(date) AS day, \n",
    "                                        WEEKOFYEAR(date) AS week, \n",
    "                                        DAYOFWEEK(date) as weekday,\n",
    "                                        DAYOFYEAR(date) year_day\n",
    "\n",
    "                                FROM time\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+---+----+-------+--------+\n",
      "|      date|year|month|day|week|weekday|year_day|\n",
      "+----------+----+-----+---+----+-------+--------+\n",
      "|2016-08-17|2016|    8| 17|  33|      4|     230|\n",
      "|2016-04-22|2016|    4| 22|  16|      6|     113|\n",
      "|2016-08-08|2016|    8|  8|  32|      2|     221|\n",
      "|2016-08-20|2016|    8| 20|  33|      7|     233|\n",
      "|2016-09-11|2016|    9| 11|  36|      1|     255|\n",
      "|2016-07-06|2016|    7|  6|  27|      4|     188|\n",
      "|2016-05-21|2016|    5| 21|  20|      7|     142|\n",
      "|2016-04-15|2016|    4| 15|  15|      6|     106|\n",
      "|2016-07-23|2016|    7| 23|  29|      7|     205|\n",
      "|2016-04-18|2016|    4| 18|  16|      2|     109|\n",
      "|2069-05-03|2069|    5|  3|  18|      6|     123|\n",
      "|2016-06-08|2016|    6|  8|  23|      4|     160|\n",
      "|2016-04-09|2016|    4|  9|  14|      7|     100|\n",
      "|2016-07-30|2016|    7| 30|  30|      7|     212|\n",
      "|2016-05-16|2016|    5| 16|  20|      2|     137|\n",
      "|2016-08-07|2016|    8|  7|  31|      1|     220|\n",
      "|2016-09-14|2016|    9| 14|  37|      4|     258|\n",
      "|2016-04-11|2016|    4| 11|  15|      2|     102|\n",
      "|2016-07-19|2016|    7| 19|  29|      3|     201|\n",
      "|2016-04-12|2016|    4| 12|  15|      3|     103|\n",
      "+----------+----+-----+---+----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_dim.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# check record counts\n",
    "def perform_quality_check1(input_df, table_name):\n",
    "    \"\"\"\n",
    "    Check data completeness by ensuring that there are records in each table.\n",
    "    \n",
    "    Parameters:\n",
    "     input_df: spark dataframe to check counts on.\n",
    "     table_name: name of table\n",
    "    \"\"\"\n",
    "    \n",
    "    record_count = input_df.count()\n",
    "\n",
    "    if (record_count == 0):\n",
    "        print(\"Data quality check failed for {} table with zero records!\".format(table_name))\n",
    "    else:\n",
    "        print(\"Data quality check is done for {} table with {} records.\".format(table_name, record_count))\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# check duplicated records\n",
    "def perform_quality_check2(input_df, table_name):\n",
    "    \"\"\"\n",
    "    Check for data duplication in each table.\n",
    "    \n",
    "    Parameters:\n",
    "     input_df: spark dataframe to check counts on.\n",
    "     table_name: name of table\n",
    "    \"\"\"\n",
    "    \n",
    "    duplicated_count = input_df.toPandas().duplicated().sum()\n",
    "\n",
    "    if (duplicated_count == 0):\n",
    "        print(\"Data quality check is done for {} table with No duplicated records\".format(table_name, duplicated_count))\n",
    "    else:\n",
    "        print(\"Data quality check failed for {} table with duplicated records!\".format(table_name))\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Perform data quality check for data completness*********\n",
      "Data quality check is done for immigration table with 2213029 records.\n",
      "Data quality check is done for airport table with 14575 records.\n",
      "Data quality check is done for Demographics table with 2875 records.\n",
      "Data quality check is done for temperature table with 189471 records.\n",
      "Data quality check is done for time table with 173 records.\n"
     ]
    }
   ],
   "source": [
    "tables = {\n",
    "    \"immigration\": immigration_fact,\n",
    "    \"airport\": airports_dim,\n",
    "    \"Demographics\": demographics_dim,\n",
    "    \"temperature\": temperature_dim,\n",
    "    \"time\": time_dim      \n",
    "}\n",
    "print(\"***********Perform data quality check for data completness*********\")\n",
    "for table_name, table in tables.items():\n",
    "    perform_quality_check1(table, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Perform data quality check for data Duplication*********\n",
      "Data quality check is done for immigration table with No duplicated records\n",
      "Data quality check is done for airport table with No duplicated records\n",
      "Data quality check is done for Demographics table with No duplicated records\n",
      "Data quality check is done for temperature table with No duplicated records\n",
      "Data quality check is done for time table with No duplicated records\n"
     ]
    }
   ],
   "source": [
    "print(\"***********Perform data quality check for data Duplication*********\")\n",
    "for table_name, table in tables.items():\n",
    "    perform_quality_check2(table, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    " * **Due to the massive amount of immigration dataset ( around 3M rows), we use Apache spark to handle such huge amount of data**\n",
    " * **Also we use pandas with other relativly small datasets to handle it**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* Propose how often the data should be updated and why.\n",
    " * **It should be updated monthly as the main dataset (I94 immigration dataset is updated monthly**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    "1. The data was increased by 100x.\n",
    " \n",
    " * **We will still using spark as it is a good choice for handling big data but we will increase the number of nodes in our cluster, and we have to use AWS to store data in S3 and Redshift**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "2. The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * **We would manage the ETL pipeline in a DAG from Apache Airflow. This would ensure that the pipeline runs in time, perform data quality checks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    " 3. The database needed to be accessed by 100+ people.\n",
    "  * **we would move our analytics database into Amazon Redshift to be easily accessed by all people**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
